{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 光伏发电预测\n",
    "\n",
    "fork https://github.com/irutheu/LSTM-power-forecasting.git 仓库。\n",
    "仓库中使用LSTM模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# model itself\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from keras.losses import mean_absolute_percentage_error\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/pvdaq-2012-2014/pvdaq_2012_2014_hourly.csv', header=0, infer_datetime_format=True, parse_dates=['Date-Time'], index_col=['Date-Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to use for forecasting\n",
    "cols = ['ambient_temp', 'inverter_temp', 'module_temp', 'poa_irradiance', \n",
    "        'relative_humidity', 'wind_direction', 'wind_speed']\n",
    "time_indexes = [df.index.hour, df.index.month]\n",
    "# we will forecast dc power output\n",
    "target = ['dc_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array stacking\n",
    "def create_sequence(df, cols, target):\n",
    "  seqs = []\n",
    "  for col in cols:\n",
    "    seq = df[col].values.reshape((len(df[col]), 1))\n",
    "    seqs.append(seq)\n",
    "  for index in time_indexes:\n",
    "    seq = index.values.reshape((len(df[col]), 1))\n",
    "    seqs.append(seq)\n",
    "  seq = df[target].values.reshape((len(df[target]), 1))\n",
    "  for i in range(len(seq)):\n",
    "    if seq[i] < 0:\n",
    "      seq[i] = 0\n",
    "  seqs.append(seq)\n",
    "  dataset = np.hstack((seqs))  \n",
    "  return dataset\n",
    "\n",
    "dataset = (create_sequence(df, cols, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single step multivariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    "  X, y = list(), list()\n",
    "  for i in range(len(sequence)):\n",
    "    end_ix = i + n_steps\n",
    "    # check if we are not beyond range\n",
    "    if end_ix > len(sequence)-1:\n",
    "      break\n",
    "    seq_x, seq_y = sequence[i:end_ix, :], sequence[end_ix ,-1]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(dataset, 4)\n",
    "print(X. shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1), y[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence_multi(sequence, n_steps, n_steps_out):\n",
    "  X, y = list(), list()\n",
    "  for i in range(len(sequence)):\n",
    "    end_ix = i + n_steps\n",
    "    out_ix = end_ix + n_steps_out\n",
    "    # boundary check\n",
    "    if out_ix > len(sequence):\n",
    "      break\n",
    "    seq_x, seq_y = sequence[i:end_ix, :], sequence[end_ix:out_ix, -1]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence_multi(dataset, 12, 6)\n",
    "print(X.shape, y.shape)\n",
    "print(X[0][0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_steps is amount of time steps per sample\n",
    "# n_steps_out is the amount of time steps model has to forecast\n",
    "n_steps, n_steps_out = 24, 6 # 24, 6\n",
    "# number of features in each timestep\n",
    "n_features=X.shape[2]\n",
    "X, y = split_sequence_multi(dataset, n_steps, n_steps_out)\n",
    "train_X, train_y = X[:-2000,:], y[:-2000,:]\n",
    "val_X, val_y = X[-2000:-1000,:], y[-2000:-1000,:]\n",
    "test_X, test_y = X[-1000:,:], y[-1000:,:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, activation='tanh', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(256, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dense(64)) # , activation='relu'\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(n_steps_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamw', loss='mse')\n",
    "# model = build_model()\n",
    "\n",
    "history = model.fit(train_X, train_y, batch_size=32, epochs=20, validation_data=(val_X, val_y))\n",
    "# A stateful recurrent model is one for which the internal states (memories) \n",
    "# obtained after processing a batch of samples are reused as initial states for the samples of the next batch\n",
    "\n",
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Forecasting Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.savefig('history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error\n",
    "def sMAPE(y_true, y_pred):\n",
    "    #Symmetric mean absolute percentage error\n",
    "    return 100 * K.mean(K.abs(y_pred - y_true) / (K.abs(y_pred) + K.abs(y_true)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model.predict(train_X)\n",
    "mse = mean_squared_error(train_y, predictions1)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(train_y, predictions1)\n",
    "#mape = mean_absolute_percentage_error(predictions1, test_y)\n",
    "print(round(mse), round(rmse), round(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_y, predictions)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(test_y, predictions)\n",
    "# mape = mean_absolute_percentage_error(test_y, predictions)\n",
    "# smape = sMAPE(test_y, predictions) \n",
    "# print(round(mse), round(rmse), round(mae))\n",
    "print(mse, rmse, mae)\n",
    "# for i in range(len(test_y)):\n",
    "#   print(\"prediction\" + str(i))\n",
    "#   for j in range(n_steps_out):\n",
    "#     print(int(abs(test_y[i][j]-predictions[i][j])), int(test_y[i][j]), int(predictions[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[0], test_y[6], test_y[12], test_y[18], test_y[24]\n",
    "predictions[0], predictions[6], predictions[12], predictions[18], predictions[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq1 = []\n",
    "pred_seq1 = []\n",
    "for i in range(36):\n",
    "  test_seq1 = np.concatenate((test_seq1, test_y[i*6]))\n",
    "  pred_seq1 = np.concatenate((pred_seq1, predictions[i*6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "blue_line = mlines.Line2D([], [], color='blue', marker='s',\n",
    "                          markersize=5, label='label')\n",
    "red_line = mlines.Line2D([], [], color='red', marker='p',\n",
    "                          markersize=5, label='prediction')\n",
    "\n",
    "#plt.legend(handles=[blue_line, red_line])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(test_seq1, 'b-s')\n",
    "plt.plot(pred_seq1, 'r--p')\n",
    "plt.legend(handles=[blue_line, red_line])\n",
    "plt.savefig('figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.concatenate((test_y[0], test_y[6], test_y[12], test_y[18], test_y[24], test_y[30], test_y[36]))\n",
    "pred_seq = np.concatenate((predictions[0], predictions[6], predictions[12], predictions[18], predictions[24], predictions[30], predictions[36]))\n",
    "plt.plot(test_seq)\n",
    "plt.plot(pred_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model  \n",
    "   \n",
    "### Build, Load, and Compile your model  \n",
    "   \n",
    "#  plot_model(model, to_file='model.png', show_layer_names=True)\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_activations=True)\n",
    "model.save(\"model.keras\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
